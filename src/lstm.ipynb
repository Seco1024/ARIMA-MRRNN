{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers, metrics, backend\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lib import lstm_tools\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ARIMA input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.path.pardir))\n",
    "data = []\n",
    "files_dir = '../data/VARMA_ARIMA/filtered_after_ARIMA/'\n",
    "d = 0\n",
    "\n",
    "for file in os.listdir(files_dir):\n",
    "    file_path = os.path.join(files_dir, file)\n",
    "    df = pd.read_csv(file_path, index_col='date', parse_dates=True)\n",
    "    if not d:\n",
    "        dates = df.index\n",
    "        d = 1\n",
    "    if np.isnan(df).any().any() or np.isnan(df).any().any() :\n",
    "        print(file)\n",
    "        continue\n",
    "    data.append(df.reset_index(drop=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **預處理：MinMax Scaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **預處理：切割資料集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, train_X, train_y, val_X, val_y, test_X, test_y = [],[],[],[],[],[],[],[]\n",
    "past_n = 5\n",
    "future_n = 1\n",
    "\n",
    "for pair_corr in data:\n",
    "    # scaler.fit(pair_corr)\n",
    "    # pair_corr = scaler.transform(pair_corr)\n",
    "    for i in range(past_n, len(pair_corr) - future_n + 1):\n",
    "        X.append(pair_corr[i - past_n:i])\n",
    "        y.append(pair_corr[i + future_n - 1:i + future_n]['close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([X[i].values.tolist() for i in range(len(X))])\n",
    "y = np.array([a.values.tolist() for a in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = X[:int(len(X) * 0.7)], y[:int(len(X) * 0.7)]\n",
    "val_X, val_y = X[int(len(X) * 0.7):int(len(X) * (0.7 + 0.15))], y[int(len(X) * 0.7):int(len(X) * (0.7 + 0.15))]\n",
    "test_X, test_y = X[int(len(X) * (0.7 + 0.15)):], y[int(len(X) * (0.7 + 0.15)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (train_X.shape[1], train_X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.shape[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **模型訓練**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(x_shape, y_shape, neurons, dropout_rate, is_doubled_layer, is_regularized):\n",
    "    model = Sequential()\n",
    "    if is_doubled_layer:\n",
    "        model.add(LSTM(neurons, input_shape=x_shape, return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(LSTM(int(neurons/2), input_shape=x_shape, return_sequences=True))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    else:\n",
    "        model.add(LSTM(neurons, input_shape=x_shape))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    if is_regularized:\n",
    "        model.add(Dense(x_shape[1], 'relu',  kernel_regularizer=regularizers.l2(0.01)))\n",
    "    else:\n",
    "        model.add(Dense(x_shape[1], 'relu'))\n",
    "    model.add(Dense(y_shape, 'linear'))\n",
    "    \n",
    "    adam = Adam(lr=0.001)\n",
    "    mse = MeanSquaredError()\n",
    "    model.compile(optimizer=adam, loss=mse, metrics=[metrics.MSE, metrics.MAE])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_lstm_model(input_shape, 1, 64, 0.5, 0, 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(parent_dir, 'models/a.h5')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint_callback = ModelCheckpoint(checkpoint_dir, monitor='val_loss', verbose=1, mode='min', save_best_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_X, train_y, epochs=100, batch_size=128, validation_data=(val_X, val_y), callbacks=[early_stopping, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
